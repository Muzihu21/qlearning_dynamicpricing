# -*- coding: utf-8 -*-
"""train_qlearning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W863RgoMLCIOFmb-dbt93OUDrlT09me4
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
from q_learning_env import PenjualanEnv

# Hyperparameter
alpha = 0.1
gamma = 0.9
epsilon = 0.1
epsilon = 1.0          # mulai dari eksplorasi penuh
epsilon_min = 0.05     # eksplorasi minimum
decay_rate = 0.995     # seberapa cepat eksplorasi menurun
episodes = 10000

# Load env
env = PenjualanEnv()
env.unique_states = list(set(env.states))
env.n_states = len(env.unique_states)

state_to_index = {s: i for i, s in enumerate(env.unique_states)}
q_table = np.zeros((env.n_states, env.n_actions))

rewards_per_episode = []

for episode in range(episodes):
    state = env.reset()
    total_reward = 0
    done = False

    while not done:
        state_idx = state_to_index[state]

        # Epsilon-greedy
        if np.random.rand() < epsilon:
            action = np.random.randint(env.n_actions)
        else:
            action = np.argmax(q_table[state_idx])

        next_state, reward, done = env.step(action)
        next_state_idx = state_to_index[next_state]

        # Update Q-value
        # penerapan Temporal Difference
        q_table[state_idx, action] += alpha * (
            reward + gamma * np.max(q_table[next_state_idx]) - q_table[state_idx, action]
        )

        state = next_state
        total_reward += reward

    rewards_per_episode.append(total_reward)

    if episode % 100 == 0:
        print(f"Episode {episode}, Total Reward: {total_reward}")

# Simpan Q-table
np.save("q_table.npy", q_table)

# Buat folder visualisasi kalau belum ada
os.makedirs("visualizations", exist_ok=True)

# Plot dan simpan grafik reward
plt.plot(rewards_per_episode)
plt.xlabel("Episode")
plt.ylabel("Total Reward")
plt.title("Q-Learning Training Reward")
plt.savefig("visualizations/reward_plot.png")
plt.close()

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.plot(rewards_per_episode)
plt.xlabel("Episode")
plt.ylabel("Total Reward")
plt.title("Reward per Episode (Q-Learning Training)")
plt.grid(True)
plt.show()

import numpy as np
from q_learning_env import PenjualanEnv

# Load Q-table hasil training
q_table = np.load("q_table.npy")

# Load ulang environment
env = PenjualanEnv()
env.unique_states = list(set(env.states))
state_to_index = {s: i for i, s in enumerate(env.unique_states)}

# Simulasi policy Q-table
episodes = 100
total_penjualan_units = []

for _ in range(episodes):
    state = env.reset()
    total_units = 0
    done = False

    while not done:
        state_idx = state_to_index[state]
        action = np.argmax(q_table[state_idx])  # Ambil aksi terbaik

        next_state, reward, done = env.step(action)

        # Ambil jumlah unit penjualan dari state (penjualan_level)
        harga_idx, penjualan_lvl = next_state
        total_units += penjualan_lvl  # anggap penjualan_lvl = jumlah unit (diskret)

        state = next_state

    total_penjualan_units.append(total_units)

# Visualisasikan
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.plot(total_penjualan_units)
plt.xlabel("Episode")
plt.ylabel("Total Penjualan Unit")
plt.title("Total Penjualan per Episode Setelah Dynamic Pricing")
plt.grid(True)
plt.show()

# Optional: Cetak rata-rata penjualan
avg_penjualan = np.mean(total_penjualan_units)
print(f"Rata-rata penjualan unit/episode: {avg_penjualan:.2f}")

df_reward = pd.DataFrame({
    "Episode": range(1, len(rewards_per_episode)+1),
    "Reward": rewards_per_episode
})

# Tambahkan kolom 'Batch 100-an' untuk grup visual tren
df_reward["Batch"] = ((df_reward["Episode"] - 1) // 100) * 100 + 1

# Agregasi reward per 100 episode
reward_aggregated = df_reward.groupby("Batch")["Reward"].sum().reset_index()

# Hitung total omzet keseluruhan
total_omzet_training = df_reward["Reward"].sum()

# Visualisasi tren reward (per 100 episode)
plt.figure(figsize=(10, 5))
plt.plot(reward_aggregated["Batch"], reward_aggregated["Reward"], marker='o', color='royalblue')
plt.title(f"Tren Reward Selama Training\nTotal Omzet: Rp {total_omzet_training:,.0f}")

import seaborn as sns
# Load Q-table
q_table = np.load("q_table.npy")

# Init env
env = PenjualanEnv()
env.unique_states = list(set(env.states))
state_to_index = {s: i for i, s in enumerate(env.unique_states)}

episodes = 100
agent_rewards = []
random_rewards = []

for _ in range(episodes):
    # --- Agent Q-learning
    state = env.reset()
    total_reward = 0
    done = False
    while not done:
        state_idx = state_to_index[state]
        action = np.argmax(q_table[state_idx])
        state, reward, done = env.step(action)
        total_reward += reward
    agent_rewards.append(total_reward)

    # --- Random Strategy
    state = env.reset()
    total_reward = 0
    done = False
    while not done:
        action = np.random.randint(env.n_actions)
        state, reward, done = env.step(action)
        total_reward += reward
    random_rewards.append(total_reward)

# --- Visualisasi
plt.figure(figsize=(8, 6))
sns.boxplot(data=[random_rewards, agent_rewards], palette=["salmon", "skyblue"])
plt.xticks([0, 1], ["Tanpa Strategi", "Q-Learning Agent"])
plt.ylabel("Total Reward (Omzet)")
plt.title("ðŸ“Š Perbandingan Omzet\nRandom vs Q-Learning")
plt.grid(True)
plt.tight_layout()
plt.savefig("visualizations/compare_omzet_boxplot.png")
plt.show()

# Rata-rata
print(f"Rata-rata Random : Rp {np.mean(random_rewards):,.0f}")
print(f"Rata-rata Q-Learn: Rp {np.mean(agent_rewards):,.0f}")

np.save("q_table.npy", q_table)
np.save("rewards_per_episode.npy", rewards_per_episode)
print("âœ… Q-table dan reward per episode berhasil disimpan.")